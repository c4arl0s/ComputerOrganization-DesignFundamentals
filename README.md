# Computer Organization and Design Fundamentals

1. [Chapter One: Digital Signals and Systems](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)
2. [Chapter Two: Numbering Systems]()
3. [Chapter Three: Binary Math and Signed Representations]()
4. [Chapter Four: Logic Functions and Gates]()
5. [Chapter Five: Boolean Algebra]()
6. [Chapter Six: Standard Boolean Expression Formats]()
7. [Chapter Seven: Karnaugh Maps]()
8. [Chapter Eight: Combinational Logic Applications]()
9. [Chapter Nine: Binary Operation Applications]()
10.[ Chapter Ten: Memory Cells]()
11.[ Chapter Eleven: State Machines]()
12.[ Chapter Twelve: Memory Organization]()
13.[ Chapter Thirteen: Memory Hierarchy]()
14.[ Chapter Fourteen: Serial Protocol Basics]()
15.[ Chapter Fifteen: Introduction to Processor Architecture]()
16.[ Chapter Sixteen: Intel 80x86 Base Architecture]()

# 1. [Chapter One: Digital Signals and Systems](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#computer-organization-and-design-fundamentals)
 * [1.1 Should Software Engineers Worry About Hardware?](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-11-should-software-engineers-worry-about-hardware)
 * [1.2 Non-Digital Signal](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-12-non-digital-signal)
 * [1.3 Digital Signals](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-13-digital-signals)
 * [1.4 Conversion Systems](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-14-conversion-systems)
 * [1.5 Representation of Digital Signals](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-15-representation-of-digital-signals)
 * [1.6 Types of Digital Signals](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-16-types-of-digital-signals)
 * [1.6.1 Edges](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-161-edges)
 * [1.6.2 Pulses](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-162-pulses)
 * [1.6.3 Non-Periodic Pulse Trains](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-163-non-periodic-pulse-trains)
 * [1.6.4 Periodic Pulse Trains](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-164-periodic-pulse-trains)
 * [1.6.5 Pulse-Width Modulation](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-165-pulse-width-modulation)
 * [1.7 Unit Prefixes](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-17-unit-prefixes)
 * [1.8 What's Next?](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-18-whats-next)
 * [Problems](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#-problems)

# 2. [Chapter Two: Numbering Systems]()
 * [2.1 Unsigned Binary Counting]()
 * [2.2 Binary Terminology]()
 * [2.3 Unsigned Binary to Decimal Conversion]()
 * [2.4 Decimal to Unsigned Binary Conversion]()
 * [2.5 Binary Representation of Analog Values]()
 * [2.6 Sampling Theory]()
 * [2.7 Hexadecimal Representation]()
 * [2.8 Binary Coded Decimal]()
 * [2.9 Gray Codes]()
 * [2.10 What's Next?]()
 * [Problems]()

# 3. [Chapter Three: Binary Math and Signed Representations]()
 * [3.1 Binary Addition]()
 * [3.2 Binary Subtraction]()
 * [3.3 Binary Complements]()
 * [3.3.1 One's Complement]()
 * [3.3.2 Two's Complement]()
 * [3.3.3 Most Significant Bit as a Sign Indicator]()
 * [3.3.4 Signed Magnitude]()
 * [3.3.5 MSB and Number of Bits]()
 * [3.3.6 Issues Surrounding the Conversion of Binary Numbers. 52 ]()
 * [3.3.7 Minimums and Maximums]()
 * [3.4 Floating Point Binary]()
 * [3.5 Hexadecimal Addition]()
 * [3.6 BCD Addition]()
 * [3.7 Multiplication and Division by Powers of Two]()
 * [3.8 Easy Decimal to Binary Conversion Trick]()
 * [3.9 Arithmetic Overflow]()
 * [3.10 What's Next?]()
 * [Problems]()

# 4. [Chapter Four: Logic Functions and Gates]()
 * [4.1 Logic Gate Basics]()
 * [4.1.1 NOT Gate]()
 * [4.1.2 AND Gate]()
 * [4.1.3 OR Gate]()
 * [4.1.4 Exclusive-OR (XOR) Gate]()
 * [4.2 Truth Tables]()
 * [4.3 Timing Diagrams for Gates]()
 * [4.4 Combinational Logic]()
 * [4.5 Truth Tables for Combinational Logic]()
 * [4.6 What's Next?]()
 * [Problems]()

# 5. [Chapter Five: Boolean Algebra]()
 * [5.1 Need for Boolean Expressions]()
 * [5.2 Symbols of Boolean Algebra]()
 * [5.3 Boolean Expressions of Combinational Logic]()
 * [5.4 Laws of Boolean Algebra]()
 * [5.5 Rules of Boolean Algebra]()
 * [5.5.1 NOT Rule]()
 * [5.5.2 OR Rules]()
 * [5.5.3 AND Rules]()
 * [5.5.4 XOR Rules]()
 * [5.5.5 Derivation of Other Rules]()
 * [5.6 Simplification]()
 * [5.7 DeMorgan's Theorem]()
 * [5.8 What's Next?]()
 * [Problems]()

# 6. [Chapter Six: Standard Boolean Expression Formats]()
 * [6.1 Sum-of-Products]()
 * [6.2 Converting an SOP Expression to a Truth Table]()
 * [6.3 Converting a Truth Table to an SOP Expression]()
 * [6.4 Product-of-Sums]()
 * [6.5 Converting POS to Truth Table]()
 * [6.6 Converting a Truth Table to a POS Expression]()
 * [6.7 NAND-NAND Logic]()
 * [6.8 What's Next?]()
 * [Problems]()

# 7. [Chapter Seven: Karnaugh Maps]()
 * [7.1 The Karnaugh Map]()
 * [7.2 Using Karnaugh Maps]()
 * [7.3 "Don't Care" Conditions in a Karnaugh Map]()
 * [7.4 What's Next?]()
 * [Problems]()

# 8. [Chapter Eight: Combinational Logic Applications]()
 * [8.1 Adders]()
 * [8.2 Seven-Segment Displays]()
 * [8.3 Active-Low Signals]()
 * [8.4 Decoders]()
 * [8.5 Multiplexers]()
 * [8.6 Demultiplexers]()
 * [8.7 Integrated Circuits]()
 * [8.8 What's Next?]()
 * [Problems]()

# 9. [Chapter Nine: Binary Operation Applications]()
 * [9.1 Bitwise Operations]()
 * [9.2 Comparing Bits with XOR]()
 * [9.3 Parity]()
 * [9.4 Checksum]()
 * [9.5 Cyclic Redundancy Check]()
 * [9.5.1 CRC Process]()
 * [9.5.2 CRC Implementation]()
 * [9.6 Hamming Code]()
 * [9.7 What's Next?]()
 * [Problems]()

# 10.[ Chapter Ten: Memory Cells]()
 * [10.1 New Truth Table Symbols]()
 * [10.1.1 Edges/Transitions]()
 * [10.1.2 Previously Stored Values]()
 * [10.1.3 Undefined Values]()
 * [10.2 The S-R Latch]()
 * [10.3 The D Latch]()
 * [10.4 Divide-By-Two Circuit]()
 * [10.5 Counter]()
 * [10.6 Parallel Data Output]()
 * [10.7 What's Next?]()
 * [Problems]()

# 11.[ Chapter Eleven: State Machines]()
 * [11.1 Introduction to State Machines]()
 * [11.1.1 States]()
 * [11.1.2 State Diagrams]()
 * [11.1.3 Errors in State Diagrams]()
 * [11.1.4 Basic Circuit Organization]()
 * [11.2 State Machine Design Process]()
 * [11.3 Another State Machine Design: Pattern Detection]()
 * [11.4 Mealy Versus Moore State Machines]()
 * [11.5 What's Next?]()
 * [Problems]()

# 12.[ Chapter Twelve: Memory Organization]()
 * [12.1 Early Memory]()
 * [12.2 Organization of Memory Device]()
 * [12.3 Interfacing Memory to a Processor]()
 * [12.3.1 Buses]()
 * [12.3.2 Memory Maps]()
 * [12.3.3 Address Decoding]()
 * [12.3.4 Chip Select Hardware]()
 * [12.4 Memory Mapped Input/Output]()
 * [12.5 Memory Terminology]()
 * [12.5.1 Random Access Memory]()
 * [12.5.2 Read Only Memory]()
 * [12.5.3 Static RAM versus Dynamic RAM]()
 * [12.5.4 Types of DRAM and Their Timing]()
 * [12.5.5 Asynchronous vs. Synchronous Memory]()
 * [12.6 What's Next?]()
 * [Problems]()

# 13.[ Chapter Thirteen: Memory Hierarchy]()
 * [13.1 Characteristics of the Memory Hierarchy]()
 * [13.2 Physical Characteristics of a Hard Drive]()
 * [13.2.1 Hard Drive Read/Write Head]()
 * [13.2.2 Data Encoding]()
 * [13.2.3 Hard Drive Access Time]()
 * [13.2.4 S.M.A.R.T.]()
 * [13.3 Organization of Data on a Hard Drive]()
 * [13.4 Cache RAM]()
 * [13.4.1 Cache Organization]()
 * [13.4.2 Dividing Memory into Blocks]()
 * [13.4.3 Cache Operation]()
 * [13.4.4 Cache Characteristics]()
 * [13.4.5 Cache Mapping Functions]()
 * [13.4.6 Cache Write Policy]()
 * [13.5 Registers]()
 * [13.6 What's Next?]()
 * [Problems]()

# 14.[ Chapter Fourteen: Serial Protocol Basics]()
 * [14.1 OSI Seven-Layer Network Model]()
 * [14.2 Serial versus Parallel Data Transmission]()
 * [14.3 Anatomy of a Frame or Packet]()
 * [14.4 Sample Protocol: IEEE 802.3 Ethernet]()
 * [14.5 Sample Protocol: Internet Protocol]()
 * [14.6 Sample Protocol: Transmission Control Protocol]()
 * [14.7 Dissecting a Frame]()
 * [14.8 Additional Resources]()
 * [14.9 What's Next?]()
 * [Problems]()

# 15.[ Chapter Fifteen: Introduction to Processor Architecture]()
 * [15.1 Organization versus Architecture]()
 * [15.2 Components]()
 * [15.2.1 Bus]()
 * [15.2.2 Registers]()
 * [15.2.3 Flags]()
 * [15.2.4 Buffers]()
 * [15.2.5 The Stack]()
 * [15.2.6 I/O Ports]()
 * [15.3 Processor Level]()
 * [15.4 CPU Level]()
 * [15.5 Simple Example of CPU Operation]()
 * [15.6 Assembly and Machine Language]()
 * [15.7 Big-Endian/Little-Endian]()
 * [15.8 Pipelined Architectures]()
 * [15.9 Passing Data To and From Peripherals]()
 * [15.9.1 Memory-Mapped I/O]()
 * [15.9.2 Polling]()
 * [15.9.3 Interrupts]()
 * [15.9.4 Direct Memory Access]()
 * [15.9.5 I/O Channels and Processors]()
 * [15.10 What's Next?]()
 * [Problems]()

# 16.[ Chapter Sixteen: Intel 80x86 Base Architecture]()
 * [16.1 Why Study the 80x86?]()
 * [16.2 Execution Unit]()
 * [16.2.1 General Purpose Registers]()
 * [16.2.2 Address Registers]()
 * [16.2.3 Flags]()
 * [16.2.4 Internal Buses]()
 * [16.3 Bus Interface Unit]()
 * [16.3.1 Segment Addressing]()
 * [16.3.2 Instruction Queue]()
 * [16.4 Memory versus I/O Ports]()
 * [16.5 What's Next?]()
 * [Problems]()

# 17.[ Chapter Seventeen: Intel 80x86 Assembly Language]()
 * [17.1 Assemblers versus Compilers]()
 * [17.2 Components of a Line of Assembly Language]()
 * [17.3 Assembly Language Directives]()
 * [17.3.1 SEGMENT Directive]()
 * [17.3.2 .MODEL, .STACK, .DATA, and .CODE Directives . 380 ]()
 * [17.3.3 PROC Directive]()
 * [17.3.4 END Directive]()
 * [17.3.5 Data Definition Directives]()
 * [17.3.6 EQU Directive]()
 * [17.4 80x86 Opcodes]()
 * [17.4.1 Data Transfer]()
 * [17.4.2 Data Manipulation]()
 * [17.4.3 Program Control]()
 * [17.4.4 Special Operations]()
 * [17.5 Addressing Modes]()
 * [17.5.1 Register Addressing]()
 * [17.5.2 Immediate Addressing]()
 * [17.5.3 Pointer Addressing]()
 * [17.6 Sample 80x86 Assembly Language Programs]()
 * [17.7 Additional 80x86 Programming Resources]()
 * [17.8 What's Next?]()
 * [Problems]()


# Computer Organization and Design Fundamentals

# 1. [Chapter One: Digital Signals and Systems](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

Knowing how to design and build a computer may not be vital to the computer professional, but it goes a long way toward improving their skills, but example, making them better drivers.

The principles of computer organization provide tools to create better designs.

	* System Design Tools.
	* Software Design Tools.
	* Improved troubleshooting skills.
	* Interconnectivity
	* Marketability

> When you control parts design, you can integrate the whole package much more elegantly.

# * [1.1 Should Software Engineers Worry About Hardware?](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)


![Screen Shot 2020-06-05 at 15 23 34](https://user-images.githubusercontent.com/24994818/83919628-9f43fd00-a740-11ea-910f-f5257759b79e.png)

# * [1.2 Non-Digital Signal](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

The real world is analog. When values such as temperature or weight change over time, they follow what is called a **continuous curve**. It is sufficient to say that analog values represent a continuous signal with infinitesimal resolution.

# * [1.3 Digital Signals](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

There is such a thing as an analog computer, a computer that processes information using analog levels of electricity or the positions of mechanical devices. Now computers represent an analog value by converting it to a number with a fixed resolution. This measurement is referred to as a **digital value**.

![Screen Shot 2020-06-06 at 13 03 35](https://user-images.githubusercontent.com/24994818/83951299-269f7800-a7f6-11ea-858b-63451d4794b2.png)

The computer can only measure the signal at intervals. Each measurement is called a **sample**. The rate at which these samples are taken is called the **Sampling rate**.

![Screen Shot 2020-06-06 at 13 05 13](https://user-images.githubusercontent.com/24994818/83951333-61091500-a7f6-11ea-9c89-f0d55adb0702.png)

Two problem arise from this process: information can be lost between the measurement and information can be lost due to the **rounding** of the measurement. First, if the sampling rate is too slow, the some details of the signal may be missed.

![Screen Shot 2020-06-06 at 13 07 18](https://user-images.githubusercontent.com/24994818/83951375-ac232800-a7f6-11ea-8b82-7b3a0126502b.png)

Second, if the computer does not record with enough accuracy an error may be introduced between the actual measurement and the recorded value.

![Screen Shot 2020-06-06 at 13 08 48](https://user-images.githubusercontent.com/24994818/83951394-e42a6b00-a7f6-11ea-87a2-fff593ffe989.png)

These effects can be reduced by increasing the resolution of the measurement and increasing the sampling rate. A discussion of this can be found in Chapter 2 in the section titled "Sampling Theory"	

# * [1.4 Conversion Systems](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

The typical system used to convert an external condition such as pressure, temperature, or light intensity to a format usable by a digital system is shown in the block diagram.

![Screen Shot 2020-06-07 at 12 00 01](https://user-images.githubusercontent.com/24994818/83974936-72195b00-a8b6-11ea-8ac5-3703e364fea6.png)

The interface between the external condition and the electronics of the system is the sensor. This device converts the environmental conditions into a signal readable by analog electronics. Often, this signal is weak and is easily distorted by noise. Therefore, the output of the sensor is usually amplified and cleaned up before being converted to digital values by the Analog-to-Digital Converter (ADC).

Continuous operation of this system results in a sequence of digital measurements or samples that are stored in the computer where it can be viewed much like the table of numbers in a spreadsheet.

First benefit of digital systems: If an analog signal is transmitted over long distances, noise attaches itself to the signal. To keep the signal strong enough to reach its destination,it must be amplified. All of the noise attached itself to the signal, however, is amplified along with the original signal resulting in distortion. 

Noise cannot attach itself to a digital signal. Once an analog signal has been converted to a sequence of numbers, the signal's characteristics remain the same as long as the number don't change. Therefore, digital systems such as contemporary long-distance phone system do not suffer from degradation over long distances.

A second benefit is that once a signal is turned into a sequence of numbs, mathematical algorithms can be used to operate on the data. Disciplines such as Digital Signal Processing and the study of wavelets allow for much more accurate processing of signals that analog systems were ever able to achieve.

These advantages come at a price, however. As mentioned earlier, if the samples are taken too slowly, details of the analog input are missed. It the resolution of the samples is not fine enough, the signal may not be precisely represented with the signal values. Last of all, additional hardware is required to convert the signal from analog to digital

# * [1.5 Representation of Digital Signals](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

Digital Systems do not store numbers the way humans do. Digital systems work with numbs using millions of tiny switches called transistors. Each transistor can remember only one f two possible values, on or off. This referred to as a **binary system**.

The complexity of the computer comes in how the millions of transistors are designed to work together. The purpose of this discussion, the two values of a transistor will be referred to as **logic 1** and **logic 0**.

![Screen Shot 2020-06-08 at 18 01 42](https://user-images.githubusercontent.com/24994818/84088447-21872800-a9b2-11ea-9a44-da484e46bd53.png)

Sometimes, two or more binary lines are grouped together to perform a single function. 

![Screen Shot 2020-06-08 at 18 02 44](https://user-images.githubusercontent.com/24994818/84088508-44b1d780-a9b2-11ea-9afc-8a9e032bfa1a.png)

Alternatively, multiple lines can be combined into a more abstract representation such as the one shown in Figure 1-10

![Screen Shot 2020-06-08 at 18 04 00](https://user-images.githubusercontent.com/24994818/84088582-71fe8580-a9b2-11ea-900c-0d08793f68a6.png)

Hash marks indicate invalid or changing data. This could mean that one or all of the signals are changing their values, or that due to the nature of the electronics, the values of the data signals cannot be predicted. In the later case, the system may need to wait to allow the signals to stabilize. 

# * [1.6 Types of Digital Signals](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)
# * [1.6.1 Edges](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

A single binary signal can have one of two possible transitions as shown in figure 1-11. The first one, a transition from a logic 0 to a logic 1, is called a rising edge transition. The second one, a transition from a logic 1 to a logic 0 is called a falling edge transition.

![Screen Shot 2020-06-08 at 18 12 18](https://user-images.githubusercontent.com/24994818/84089054-9dce3b00-a9b3-11ea-82e0-76c251d12674.png)

# * [1.6.2 Pulses]()

A binary pulse occurs when a signal changes from one value to the other for a short period, then returns to its originals value. Examples of this type of signal might be the power-on or reset buttons on a computer (momentarily pressed, the released) or the button used to initialize synchronization between a PDA and a computer.

![Screen Shot 2020-06-08 at 18 13 08](https://user-images.githubusercontent.com/24994818/84089084-b9d1dc80-a9b3-11ea-8647-b3e49af21a70.png)

There are two types of pulses. The first is called a **positive-going-pulse**, and it has an idle state of logic 0 with a short pulse to logic 1. The other one, a **negative-going pulse**, has an idle state of logic 1 with a short pulse to logic 0. Both of these signals are shown in Figure-1-12.

# * [1.6.3 Non-Periodic Pulse Trains](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

Some digital signals such as the data wires of an Ethernet link or the data and address lines of a memory interface do not have a characteristic pattern in their changes between logic 1 and logic 0. These are called **non-periodic pulse trains**

![Screen Shot 2020-06-08 at 18 18 44](https://user-images.githubusercontent.com/24994818/84089414-86438200-a9b4-11ea-8c43-9d8d81090287.png)

Like music, the duration of the notes or the spaces between the notes can be longer or shorter. On the page, they do not look meaningful, but once the reader is given the tools to interpret the signal, he data they contain becomes clear.

# * [1.6.4 Periodic Pulse Trains](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

Some signals act as the heartbeat to a digital systems. Periodic pulse trains is meat to synchronized events or keep processes moving.

![Screen Shot 2020-06-09 at 13 36 54](https://user-images.githubusercontent.com/24994818/84186574-5947ab80-aa56-11ea-8d75-1381c6b0c827.png)

![Screen Shot 2020-06-09 at 13 37 49](https://user-images.githubusercontent.com/24994818/84186627-6d8ba880-aa56-11ea-9b80-2eb9cbb9f4a0.png)

Frequency = 1 / Period [seconds]

# * [1.6.5 Pulse-Width Modulation](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

The last measurement of a periodic waveform is the **duty cycle**. The duty cycle represents the percentage of time that a periodic signal is a logic 1. 

![Screen Shot 2020-06-09 at 13 40 36](https://user-images.githubusercontent.com/24994818/84186884-d07d3f80-aa56-11ea-8eda-203e280a6815.png)

Duty Cycle = ((logic 1 pulse duration) [seconds] / period [Seconds] ) * 100%

# * [1.7 Unit Prefixes](https://github.com/c4arl0s/ComputerOrganization-DesignFundamentals#1-chapter-one-digital-signals-and-systems-1)

![Screen Shot 2020-06-09 at 13 44 01](https://user-images.githubusercontent.com/24994818/84187367-8f395f80-aa57-11ea-9004-5a21b5cbac9b.png)

# * [1.8 What's Next?]()

In this chapter, we have seen how the methods that a computer uses to store and interpret values are different from the ways in which those values appear in the real world. We have also seen some of the methods used to measure and represent these digital signals.

In Chapter 2 we will see how digital values are used to represent integers. This is the first major step toward understanding some of the idiosyncrasies of computing systems such as why a compiler might restrict the values of a data type from -32,768 to 32,767. In addition, it shows how some bugs occur in program due to the misuse of data types.

# * [Problems]()

# 2. [Chapter Two: Numbering Systems]()

Chapter one discussed how computers remember numbers using transistors, tiny devices that act like switches with only two positions, on or off. A single transistor, therefore, can only remember one of two possible numbers, a one or a zero. This is not useful for anything more complex than controlling a light bulb, so for larger values, transistors are grouped together so that their combination of ones and zero can be used to represent larger numbers.

This chapter discusses some of the methods that are used to represent numbers with groups of transistors or **bits**. The reader will also be given methods for calculating the minimum and maximum values of each representation based on the number of bits in the group.

# * [2.1 Unsigned Binary Counting]()

The simplest form o numeric representation with bits is **unsigned binary**. When we count wpward through the positive integers using decimal, we start with a 0 in the one's place and increment a value until we reach the upper limit of a single digit, i.e. 9. At that point, we have run out of the "Symbols" we use to count, and we need to increment the next digit, the ten's place. We then reset the one's place to zero, and start the cycle again.

![Screen Shot 2020-06-10 at 19 12 19](https://user-images.githubusercontent.com/24994818/84330922-54feb980-ab4e-11ea-9296-cd06592b85da.png)

Figure 2-2 shows that when counting in binary, we run out of symbols quickly requiring the addition of another "place" only the second increment.

![Screen Shot 2020-06-10 at 19 13 59](https://user-images.githubusercontent.com/24994818/84330983-8e372980-ab4e-11ea-9426-aefc8ba399ea.png)

With 2 symbols for each bit, we have 2^n possible combinations of symbols, where n represents the number of bits.	

Figure 2-3 uses 5 bits to count up to decimal 17. Examine each row where a single one position is represent in the binary number. This reveals what that position represents. For example, a binary 01000 is shown to be equivalent to a decimal 8. Therefore, the fourth bit position from the right is the 8`s position.

![Screen Shot 2020-06-10 at 19 15 38](https://user-images.githubusercontent.com/24994818/84331052-c9395d00-ab4e-11ea-9d49-049aa53c66a4.png)

This information will help us develop a method for converting **unsigned binary numbers** to decimal and back to **unsigned binary**.

Some of you may recognize this as "base-2" math. This give us a method for indicating whic representation is being ued when writing a number down on paper. 

# * [2.2 Binary Terminology]()

When writing values in decimal, it is common to separate the places or positions of large numbers in groups of three digits separated by commas.

To begin with, a single place or position in a binary number is called a bit, short for binary digit. 

Th rightmost bit, the one that represents the ones places, is called the **Least Significant Bit or LSB***.

The leftmost bit, the one that represents the ones places, is called the **Most Significant Bit or MSB, 

 * Nibble - A four bit binary number. (4 bit)
 * Byte - A unit of storage of a single character, typically an eight bit (2 nibble) binary number (short for binary term)
 * Word - Typically a sixteen bit (16 bit) (2 byte) binary number.
 * Double Word - A thirty-two bit (32 bit) (2 word) binary number.

The following are some examples of each type of binary number.

Bit								1
Nibble  					10102
Byte							101001012
Word 							1010010111110000
Double Word				10100101111100001100111011101101

# * [2.3 Unsigned Binary to Decimal Conversion]()

![Screen Shot 2020-06-11 at 23 38 07](https://user-images.githubusercontent.com/24994818/84465458-a6857200-ac3c-11ea-9820-5618d0954a20.png)

It turns out that can be represented with n bits in unsigned binary is:

2^n - 1    (remember to include zero)


# * [2.4 Decimal to Unsigned Binary Conversion]()

Converting from decimal to unsigned binary is a little more complicated, but it still is not too difficult. Once again, there is a well-defined process.

![Screen Shot 2020-06-11 at 23 45 53](https://user-images.githubusercontent.com/24994818/84465879-b9e50d00-ac3d-11ea-8e5f-f82d3caac07f.png)

# * [2.5 Binary Representation of Analog Values]()

Converting unsigned (positive) integers to binary is only one of the many ways that computers represent values using binary bits. This chapter still has two more to cover, and Chapter 3 will cover even more.

This section focuses on the problems and solutions of trying to map real world values such as temperature or weight from a specified range to a binary integer. 

For example a computer that uses 8 bits to represent an integer is capable of representing 256 individual values from 0 to 255. Temperature, however, is a floating point value with unrealistic upper and lower limits. Can we get a computer to represent a temperature using eight bits ? The answer is yes, but it will cot us in the areas of resolution and range.

![Screen Shot 2020-06-12 at 19 48 08](https://user-images.githubusercontent.com/24994818/84556023-b5742f00-ace5-11ea-9863-c93f4c1d8fb5.png)

For example, does the typical bathroom scale need to measure values above 400 pounds? If not, then a digital system could use a 10-bit binary number mapped to a range fro zero to 400 pounds. A binary 00000000000 could represent zero pounds to 1111111111 could represent 400 pounds

What is needed next is a method to map the values inside the range zero to 400 pounds to the binary integers in the range of 0000000000 to 1111111111. To do this, we need a linear function defining a one-to-one mapping between each binary integer and the analog value it represents. To do this, we turn to the basic math expression for a linear function.
 
This function defines m as the rate of the change in y with respect to changes in x and b as the value y is set to when x equals 0. We can use this expression to map a binary integer x to an analog value y.

The slope of the function, m, can be calculated by dividing the range of analog values by the number of intervals defined by the n-bit binary integer. The number of intervals defined by the n-ñbit binary integer is equal to the upper limit of that binary number if it were being used as an unsigned integer 2^n ´- 1.

![Screen Shot 2020-06-12 at 19 50 08](https://user-images.githubusercontent.com/24994818/84556056-f2402600-ace5-11ea-9c82-a1b39a1c99f4.png)

![Screen Shot 2020-06-12 at 19 50 39](https://user-images.githubusercontent.com/24994818/84556063-0126d880-ace6-11ea-8a53-544ca4fa8169.png)

Lets go back to our example of the kitchen scale where the maximum analog value is 400 pounds while the minimum is zero pounds. If a 10-bit binary value is used to represent this analog value, then the number of intervals of the binary integer is 2^10-1 = 1023

m = (400 pounds - 0 pounds) / 1023 binary increments = 0.391 pounds / binary increment

That means each time the binary number increments 0110110010 goes to 0110110011 , it represents an increment in the analog value of 0.391 pounds. 

In this case you use 10 bits, now see the example whe the increment per each binary increent is required. [See example]

In some cases, the lower limit might be something other than 0. This is important especially if better accuracy is required

b = minimum analog value

![Screen Shot 2020-06-15 at 9 22 37](https://user-images.githubusercontent.com/24994818/84668938-d7d69a00-aee9-11ea-800d-c3c09de734ff.png)

# * [2.6 Sampling Theory]()

In general, an n-bit analog-to-digital converter divides the analog range into 2^n-1 increments.

![Screen Shot 2020-06-15 at 9 25 46](https://user-images.githubusercontent.com/24994818/84669200-369c1380-aeea-11ea-8695-507217c8bcba.png)

The figure shows how the addition of a bit can improve the resolution of the values represented by the binary integers.

To improve the signal's representation, the rate at which the samples are taken, the **sampling rate**, needs to be increased. 

There is also a chance of missing a higher frequency because the sampling rate is too slow. This is called **aliasing**, and there are examples of it in everyday life.

If a signal's frequency is faster than the sampling rate, then information will be lost, and the collected data will never be able to duplicate the original

![Screen Shot 2020-06-15 at 9 31 50](https://user-images.githubusercontent.com/24994818/84669929-0dc84e00-aeeb-11ea-89d8-5be9a7ea8896.png)

To avoid **aliasing**, the rate at which samples are taken must be more than twice as fast as the highest frequency you wish to capture. This is called the **Nuquist Theorem**.

# * [2.7 Hexadecimal Representation]()

To make the binary representation of numbers easier on us humans, there is a shorthand representation for binary numbers. It begins by partitioning a binary numbers into its nibbles starting at the least significant bit (LSB). 

![Screen Shot 2020-06-15 at 9 45 24](https://user-images.githubusercontent.com/24994818/84671402-f5593300-aeec-11ea-8571-03d6d2b28168.png)

![Screen Shot 2020-06-15 at 9 46 26](https://user-images.githubusercontent.com/24994818/84671517-19b50f80-aeed-11ea-89d9-3b224a04ae99.png)

![Screen Shot 2020-06-15 at 9 47 03](https://user-images.githubusercontent.com/24994818/84671586-2e91a300-aeed-11ea-86e2-67d0e5aa5285.png)


Hexadecimal provides humans with a reliable, short-hand method of writing large binary numbers.

# * [2.8 Binary Coded Decimal]()

Binary Coded Decimal allows for fast conversion to binary of integers that do not require mathematical operations.

As in hex, each decimal digit represent a nibble of the binary equivalent Table 2-2 shows the conversion between each decimal digit and the binary equivalent.

![Screen Shot 2020-06-16 at 17 48 57](https://user-images.githubusercontent.com/24994818/84835656-ae0c9880-aff9-11ea-982c-1ada5b81c4f2.png)

It is important to note that there is no algorithmic conversion between BCD and decimal. BCD is only a method for representing decimal numbers in binary.

BCD is used frequently in financial applications due to legal requirements that decimal values be **exactly** represented. 

 * It is more complex to do mathematical operations
 * May require more memory for storage
 * Implementations could use this binary code to use signed numbers.


# * [2.9 Gray Codes]()

The use of binary counting sequences is common in digital applications. For example an n-bit binary value can be used to identify the position of a rotating shaft as being within one of 2^n different arcs.

As the shaft turns, a sensor can detect which of the shaft's arcs it is aligned with by reading a digital value and associating it with a specific arc. By remembering the previous position and timing the changes between positions, a processor can also compute speed and direction.

![Screen Shot 2020-06-17 at 13 31 37](https://user-images.githubusercontent.com/24994818/84935830-ea460480-b09e-11ea-9a19-623320f4d0d7.png)

![Screen Shot 2020-06-17 at 13 32 15](https://user-images.githubusercontent.com/24994818/84935860-f92cb700-b09e-11ea-8b2a-b0c431e65af0.png)

There is a potential problem with this methods o encoding. It is possible to read the sensor at instant when more than one gap is opening or closing between its light source and sensor. When this happens, some of the bit changes may be detected while others are not. If this happens, an erroneous measurement may occur.

For example, if the shaft shown above turns clockwise toward position 101 = 5, but at the instant when the value read will be 111 = 7, indicating counter-clockwise rotation.

To solve this problem, alternate counting sequences referred to as **Gray Code** are used. These sequences have only one bit change between values. For example, the values assigned to the arcs of the above shaft could follow the sequence 000, 001, 011, 010, 110, 111, 101, 100. **This sequence is not correct numerically, but as the shaft turns, only one bit will change as the shaft turns from one position to the next**.

![Screen Shot 2020-06-17 at 13 42 51](https://user-images.githubusercontent.com/24994818/84936827-74db3380-b0a0-11ea-9853-ac464de19042.png)

![Screen Shot 2020-06-17 at 13 43 20](https://user-images.githubusercontent.com/24994818/84936867-86bcd680-b0a0-11ea-9391-10640aa31ec9.png)

Notice that exactly one bit changes in the Gray code from one row to the next and from the bottom row to the top row.

# * [2.10 What's Next?]()

In this chapter, we have covered the difference methods of representing values, specifically positive integers, using digital circuitry. In addition to counting integers, the issues surrounding the conversion of analog or "real world" values to digital were examined along with some of the problems encountered when sampling. Finally, two methods of binary representation were presented: **Hexadecimal** and **BCD**.

Chapter 3 examines the special needs surrounding the digital representation of addition, subtraction, and floating-point values. It introduces the operation of the processor in handling some arithmetic functions.

# * [Problems]()

# 3. [Chapter Three: Binary Math and Signed Representations]()

Representing numbers with bits is one thing. Doing something with them is an entirely different matter. This chapter discusses some of the basic mathematical operations that computers perform on binary numbers along with the binary representations that support those operations. These concepts will help programmers better understand the limitations of doing math with a processor, and thereby allow them to better handle problems such as the upper and lower limits of variable types, mathematical overflow, and type casting.

# * [3.1 Binary Addition]()

![Screen Shot 2020-06-17 at 17 56 10](https://user-images.githubusercontent.com/24994818/84958882-e678a900-b0c3-11ea-81d4-520065321b73.png)

![Screen Shot 2020-06-17 at 17 57 56](https://user-images.githubusercontent.com/24994818/84958979-16c04780-b0c4-11ea-945e-bf9d220eb46b.png)

![Screen Shot 2020-06-17 at 17 58 17](https://user-images.githubusercontent.com/24994818/84959006-2475cd00-b0c4-11ea-86f2-0081eb264abb.png)

![Screen Shot 2020-06-17 at 17 59 10](https://user-images.githubusercontent.com/24994818/84959084-496a4000-b0c4-11ea-9d0e-15964b586d95.png)

# * [3.2 Binary Subtraction]()

![Screen Shot 2020-06-18 at 12 56 54](https://user-images.githubusercontent.com/24994818/85055474-39ee0400-b163-11ea-9802-e48cc1fe9457.png)

![Screen Shot 2020-06-18 at 12 58 23](https://user-images.githubusercontent.com/24994818/85055592-686bdf00-b163-11ea-9e01-70635de0d2c3.png)

2^0 column: Starting at the rightmost bit, is subtracted from 1 giving us zero.
2^1 column: 0 is subtracted from 1 resulting in 1
2^2 column: 1 is subtracted from 0. Here we need to borrow from the next highest bit. The next highest digit is 1, so we subtract 1 from it and add 10 to this digit. It is shown a small 1 before the 0. This makes our subtraction 10-1 which is equals to 1. It means 2-1 = 1
2^3 column: After the borrow, we have 0-0 which equals 0. 
2^4 column: 1 - 1 = 0
2^5 column: 1 - 0 = 0
2^6 column: we find 0 - 1 again. We need to make a borrow again in the third column from the left, but the 2^7 position of the minuend is zero and does not have anything to borrow. Therefore, the next highest digit of the minuend, the 2^8 position, is borrowed from. The borrow is then cascaded down until it reaches the 2^6 position so that the subtraction may be performed.

![Screen Shot 2020-06-18 at 13 48 29](https://user-images.githubusercontent.com/24994818/85060181-69ecd580-b16a-11ea-9dfe-f448cd2650d4.png)

# * [3.3 Binary Complements]()

In decimal arithmetic, every number has an additive complement i.e., a value that when added to the original number results in a zero. For example, 5 and -5 are additive complements because 5+(-5)=0. This section describes the two primary methods used to calculate the complements of a binary value.

# * [3.3.1 One's Complement]()

Flip each bit in the original value

![Screen Shot 2020-06-19 at 18 40 28](https://user-images.githubusercontent.com/24994818/85186048-66397b80-b25c-11ea-8715-bfed77889d89.png)

The 1's complement of a value is useful for some types of digital functions, but it does not provide much of a benefit if you are looking for the additive complement. See whats happen when we add a value to its 1's complement

![Screen Shot 2020-06-19 at 18 43 38](https://user-images.githubusercontent.com/24994818/85186121-cd573000-b25c-11ea-855d-14a73293f148.png)

If the two values were additive complements, the result should be zero, right ? Well, that takes us to the 2's complement.


# * [3.3.2 Two's Complement]()


The result of adding an n-bit number to its one's complement is always an n-bit number with ones in every position. If we add 1 to that result, our new value is an n-bit number with zeros in every position and an overflow or carry to the next highest position, The (n+1)^th column which corresponding to 2^n. 

For our 8-bit example above, the result of adding 10010110 to 01101001 is 1111111. Adding 1 to this number gives us 00000000 with and overflow carry of 1 to the ninth or 2^8 column. If we restrict ourselves to 8 bits, this overflow carry canbe ignore.

So, the 2's complement of a value is found by firts taking the 1's complement, then incrementing that result by 1. 

![Screen Shot 2020-06-19 at 18 43 38](https://user-images.githubusercontent.com/24994818/85186316-eca28d00-b25d-11ea-926c-03141a2dfa11.png)

Then we can test

![Screen Shot 2020-06-19 at 18 52 11](https://user-images.githubusercontent.com/24994818/85186334-03e17a80-b25e-11ea-9a34-08d577232cfe.png)

Another example 88 - 10 = 78

88 	-	01011000
-10 -	11110110

![Screen Shot 2020-06-19 at 18 56 29](https://user-images.githubusercontent.com/24994818/85186436-98e47380-b25e-11ea-97cf-31895ccf1e62.png)

result = 2^6+2^3+2^2+2^1 = 78

![Screen Shot 2020-06-19 at 18 59 11](https://user-images.githubusercontent.com/24994818/85186497-f973b080-b25e-11ea-9480-32741f85b6be.png)

This match the result for the previous example.

Also remember, is we want to obtain the negative number of (-5) is five, so taking the two's complement you get 5.

![Screen Shot 2020-06-19 at 19 01 27](https://user-images.githubusercontent.com/24994818/85186541-4b1c3b00-b25f-11ea-84fd-0bb64b6e007a.png)

# * [3.3.3 Most Significant Bit as a Sign Indicator]()

MSB of a value can be used to indicate whether a number is positive or negative and is called a **sign bit**.

> A binary value with a 0 in the MSB position is considered positive and a binary value with a 1 in the MSB position is considered negative.

Since the MSB is being used to indicate the sign of a signed binary number, it cannot be used to represent a power of 2. If a number is said to represent a 2's complement value, only n-1 of its n bits can be used to determine the magnitude since the MSB is used for the sign.

This cuts in half the number of positive integers n bits can represent.

Special Cases ?

- Binary number with all zeros is equal to a decimal 0.
- Taking the negative of zero still gives us zero.
- In this section on minimums and maximums, we will see that an n-bit value with an MSB equal to one and all other bits equal to zero is a negative number, specifically, -2^(n-1). 
- The larges positive number represented in 2's complement has an MSB of 0 with all the remaining bits set to one. This value equals [2^(n-1) - 1]. Therefore, since 2^(n-1) is greater than [2^(n-1) -1], we cansee that there s no positive equivalent to the binary number 1000...000.

# * [3.3.4 Signed Magnitude]()

A second, less useful way to represent positive and negative binary numbers is to take the MSB and use it as a sign but, much like a plus or minus sign, and leave the remaining bits to represent the magnitude.

![Screen Shot 2020-06-21 at 18 17 00](https://user-images.githubusercontent.com/24994818/85237300-6caa2d80-b3eb-11ea-873e-66c2c4fe03b7.png)

# * [3.3.5 MSB and Number of Bits]()

Since the MSB is necessary to indicate the sign of a binary value, it is vital that we know how many bits a particular number is being represented with so we know exactly where the MSB is. In other words, the leading zeros of a binary value may have been removed making it look like the binary value is negative since it starts with a one.

# * [3.3.6 Issues Surrounding the Conversion of Binary Numbers. 52 ]()

Since computers don't use an infinite number of bits to represent values, the software must know two things before it can interpret a binary value: the number of bits and the type of binary representation being used. This usually is confusing for the novice.

![Screen Shot 2020-06-25 at 15 59 32](https://user-images.githubusercontent.com/24994818/85794897-fb28f280-b6fc-11ea-95b2-9095f53cd13d.png)

{insert explanation about another conversion}

This discussion shows that it is possible for a binary pattern of ones and zeros to have three interpretations. It All depends on how the computer has been told to interpret the value

In a programming language such as C, the way in which a computer treats a variable depends on how it is declared. Variables declared as **unsigned int** are stored in **unsigned binary notation**. Variables declared as **int** are treated as either **2's complement** or **signed magnitud depending on the processor and/or compiler.

# * [3.3.7 Minimums and Maximums]()

When using a finite number of bit positions to store information, it is vital to be able to determine the minimum and maximum values that each binary can handle. Failure to do this might result in bugs in the software you create. This section calculates the minimum and maximum values for each of the three representations discussed in this and the previous chapter using a fixed number of bits, n.

Let's begin with the most basic representation, **unsigned binary**. The smallest valye that cn be represented with **unsigned binary representation** ocurrs when all the bits equal to zero. Conversion from binary to decimal results 0+0+...+0=0, Therefore, for an n bit number

Minimum n-bit unsigned binary number = 0

The largest value that can be represented with unsigned binary representation is reached when all n bits equal to one. When we convert this value from binary to decimal, we get 2^(n-1) + 2^(n-2)+...+2^0. As was shown in Chapter 2, adding one to this expression results in 2^n.

Therefore, for an n-bit unsigned binary numberm the maximum is:

Maximum n-bit unsigned binary number = 2^n - 1

And so on.

![Screen Shot 2020-06-25 at 16 18 05](https://user-images.githubusercontent.com/24994818/85796400-83a89280-b6ff-11ea-8a0f-21f5cd6ea206.png)

So **why can 8-bit signed magnitude only represents 255 possible values instead of 256? It is because in signed magnitude 00000000 and 1000000 both represent the same number, a decimal 0.


# * [3.4 Floating Point Binary]()

Binary numbers can also ave decimal points, and to show you how, we will once again begin with decimal numbers. For decimal numbers with decimal points, the standard way to represent the digits to the right o the decimal points is to continue the powers of ten in descending order starting with -1 where 10^(-1) = 1/10 = 0.1. That means that the number 6.5342 has 5 increments of 10^(-1) (tenths), 3 increments of 10^(-2) (hundredths), 4 increments of 10^(-3) (thousandths), and 2 increments of 10^(-4) (tn-thousandths) The table below shows this graphically.

| Exponent       | 3    | 2   | 1  | 0 | -1  | -2   | -3    | -4      |
|----------------|------|-----|----|---|-----|------|-------|---------|
| Position Value | 1000 | 100 | 10 | 1 | 0.1 | 0.01 | 0.000 | 0.00001 |
| Sample Values  | 0    | 0   | 0  | 6 | 5   | 3    | 4     | 2       |

Binary representation of real numbers works the same way except that each position represents a power of two, not a power of ten

| Exponent       | 2 | 1 | 0 | -1  | -2   | -3    | -4    | -5      |
|----------------|---|---|---|-----|------|-------|-------|---------|
| Position Value | 4 | 2 | 1 | 0.5 | 0.25 | 0.125 | 0.065 | 0.03125 |
| Sample Values  | 0 | 1 | 0 | 0   | 1    | 1     | 0     | 1       |

Computers, use a form of binary more like scientific notation to represent floating-point or real numbers.

The IEEE standard 754 is used to represent real numbers on the majority of contemporary computer systems. It utilizes a 32-bit pattern to represent single-precision numbers and a 64-bit pattern to represent double-precision numbers. Each of these bit patterns is divided into three parts, each part representing a different component of the real number being stored.


![Screen Shot 2020-06-28 at 6 30 17](https://user-images.githubusercontent.com/24994818/85946267-e91b9f80-b908-11ea-9ded-c45cba8494f0.png)

Both formats work the same differing only by the number of bits used to represent each component of the real number. In general, the components of the single-precision format are substited into Equation 3.7 where the sign of the value is determined by the sign bit (0 - positive value, 1 - negative value). Note that E is in unsigned binary representation.

(+/-)1.Fx2^(E-127)


for double-precision values

(+/-)1.Fx2^(E-127)

In both cases, F is preceded with an implied '1' and a binary point.
There are, however, some special cases. These are as follows:

- Positive, E=255, F=0: represents positive infinite;
- Negative, E=255, F=0: represents negative infinite; and 
- Positive or negative, E=0, F=0; represents zero.


# * [3.5 Hexadecimal Addition]()

In decimal does not require a carry until the result goes beyond 9. Hexadecimal numbers (base 16) can be added using the same method. 

![Screen Shot 2020-06-28 at 20 36 57](https://user-images.githubusercontent.com/24994818/85964402-2b7fc380-b97f-11ea-81f9-9b86fc7f8f8c.png)

For example, in decimal, adding 5 and 7 results in 2 with a carry to the next highest position. In hexadecimal, however, 5 added to 7 dos not go beyond the range of a single digit. In this case, 5+7=(C)16 with no carry. It is not until a result greater than (F)16 is reached (a decimal (15)10) that a carry is necessary.

Example

Add (3DA32)16 to (4292F)16

|   | 1 | 1 |   | 1 |   |
|---|---|---|---|---|---|
|   | 3 | D | A | 3 | 2 |
| + | 4 | 2 | 9 | 2 | F |
|   | 8 | 0 | 3 | 6 | 1 |


# * [3.6 BCD Addition]()

When we introduced Binary Coded Decimal numbers, we said that the purpose of these numbers was to provide a quick conversion to binary that would not be used in mathematical functions. It turns out, however, that BCD numbers can be added too, there is just an additional step that occurs when each column of digits is added.

When two BCD numbers are added, the digits 1010, 1011, 1100, 1101, 1110 and 1111 must be avoided. This is done by adding an additional step anytime the binary addition of two nibbles results in one of these illegal values or if a carry is generated. When this happens, the invalid result is corrected by adding 6 to skip over the illegal values:

For example:

![Screen Shot 2020-06-29 at 19 02 54](https://user-images.githubusercontent.com/24994818/86067819-592a4280-ba3b-11ea-9f5e-3781a4914f63.png)

This step is also necessary if a carry results from a BCD addition.

![Screen Shot 2020-06-29 at 19 03 02](https://user-images.githubusercontent.com/24994818/86067822-5a5b6f80-ba3b-11ea-8dad-47c36531e207.png)

# * [3.7 Multiplication and Division by Powers of Two]()
# * [3.8 Easy Decimal to Binary Conversion Trick]()
# * [3.9 Arithmetic Overflow]()
# * [3.10 What's Next?]()
# * [Problems]()

# 4. [Chapter Four: Logic Functions and Gates]()
# * [4.1 Logic Gate Basics]()
# * [4.1.1 NOT Gate]()
# * [4.1.2 AND Gate]()
# * [4.1.3 OR Gate]()
# * [4.1.4 Exclusive-OR (XOR) Gate]()
# * [4.2 Truth Tables]()
# * [4.3 Timing Diagrams for Gates]()
# * [4.4 Combinational Logic]()
# * [4.5 Truth Tables for Combinational Logic]()
# * [4.6 What's Next?]()
# * [Problems]()

# 5. [Chapter Five: Boolean Algebra]()
# * [5.1 Need for Boolean Expressions]()
# * [5.2 Symbols of Boolean Algebra]()
# * [5.3 Boolean Expressions of Combinational Logic]()
# * [5.4 Laws of Boolean Algebra]()
# * [5.5 Rules of Boolean Algebra]()
# * [5.5.1 NOT Rule]()
# * [5.5.2 OR Rules]()
# * [5.5.3 AND Rules]()
# * [5.5.4 XOR Rules]()
# * [5.5.5 Derivation of Other Rules]()
# * [5.6 Simplification]()
# * [5.7 DeMorgan's Theorem]()
# * [5.8 What's Next?]()
# * [Problems]()

# 6. [Chapter Six: Standard Boolean Expression Formats]()
# * [6.1 Sum-of-Products]()
# * [6.2 Converting an SOP Expression to a Truth Table]()
# * [6.3 Converting a Truth Table to an SOP Expression]()
# * [6.4 Product-of-Sums]()
# * [6.5 Converting POS to Truth Table]()
# * [6.6 Converting a Truth Table to a POS Expression]()
# * [6.7 NAND-NAND Logic]()
# * [6.8 What's Next?]()
# * [Problems]()

# 7. [Chapter Seven: Karnaugh Maps]()
# * [7.1 The Karnaugh Map]()
# * [7.2 Using Karnaugh Maps]()
# * [7.3 "Don't Care" Conditions in a Karnaugh Map]()
# * [7.4 What's Next?]()
# * [Problems]()

# 8. [Chapter Eight: Combinational Logic Applications]()
# * [8.1 Adders]()
# * [8.2 Seven-Segment Displays]()
# * [8.3 Active-Low Signals]()
# * [8.4 Decoders]()
# * [8.5 Multiplexers]()
# * [8.6 Demultiplexers]()
# * [8.7 Integrated Circuits]()
# * [8.8 What's Next?]()
# * [Problems]()

# 9. [Chapter Nine: Binary Operation Applications]()
# * [9.1 Bitwise Operations]()
# * [9.2 Comparing Bits with XOR]()
# * [9.3 Parity]()
# * [9.4 Checksum]()
# * [9.5 Cyclic Redundancy Check]()
# * [9.5.1 CRC Process]()
# * [9.5.2 CRC Implementation]()
# * [9.6 Hamming Code]()
# * [9.7 What's Next?]()
# * [Problems]()

# 10. [Chapter Ten: Memory Cells]()
# * [10.1 New Truth Table Symbols]()
# * [10.1.1 Edges/Transitions]()
# * [10.1.2 Previously Stored Values]()
# * [10.1.3 Undefined Values]()
# * [10.2 The S-R Latch]()
# * [10.3 The D Latch]()
# * [10.4 Divide-By-Two Circuit]()
# * [10.5 Counter]()
# * [10.6 Parallel Data Output]()
# * [10.7 What's Next?]()
# * [Problems]()

# 11.[ Chapter Eleven: State Machines]()
# * [11.1 Introduction to State Machines]()
# * [11.1.1 States]()
# * [11.1.2 State Diagrams]()
# * [11.1.3 Errors in State Diagrams]()
# * [11.1.4 Basic Circuit Organization]()
# * [11.2 State Machine Design Process]()
# * [11.3 Another State Machine Design: Pattern Detection]()
# * [11.4 Mealy Versus Moore State Machines]()
# * [11.5 What's Next?]()
# * [Problems]()

12. [Chapter Twelve: Memory Organization]()
# * [12.1 Early Memory]()
# * [12.2 Organization of Memory Device]()
# * [12.3 Interfacing Memory to a Processor]()
# * [12.3.1 Buses]()
# * [12.3.2 Memory Maps]()
# * [12.3.3 Address Decoding]()
# * [12.3.4 Chip Select Hardware]()
# * [12.4 Memory Mapped Input/Output]()
# * [12.5 Memory Terminology]()
# * [12.5.1 Random Access Memory]()
# * [12.5.2 Read Only Memory]()
# * [12.5.3 Static RAM versus Dynamic RAM]()
# * [12.5.4 Types of DRAM and Their Timing]()
# * [12.5.5 Asynchronous vs. Synchronous Memory]()
# * [12.6 What's Next?]()
# * [Problems]()

# 13.[ Chapter Thirteen: Memory Hierarchy]()
# * [13.1 Characteristics of the Memory Hierarchy]()
# * [13.2 Physical Characteristics of a Hard Drive]()
# * [13.2.1 Hard Drive Read/Write Head]()
# * [13.2.2 Data Encoding]()
# * [13.2.3 Hard Drive Access Time]()
# * [13.2.4 S.M.A.R.T.]()
# * [13.3 Organization of Data on a Hard Drive]()
# * [13.4 Cache RAM]()
# * [13.4.1 Cache Organization]()
# * [13.4.2 Dividing Memory into Blocks]()
# * [13.4.3 Cache Operation]()
# * [13.4.4 Cache Characteristics]()
# * [13.4.5 Cache Mapping Functions]()
# * [13.4.6 Cache Write Policy]()
# * [13.5 Registers]()
# * [13.6 What's Next?]()
# * [Problems]()

# 14.[ Chapter Fourteen: Serial Protocol Basics]()
# * [14.1 OSI Seven-Layer Network Model]()
# * [14.2 Serial versus Parallel Data Transmission]()
# * [14.3 Anatomy of a Frame or Packet]()
# * [14.4 Sample Protocol: IEEE 802.3 Ethernet]()
# * [14.5 Sample Protocol: Internet Protocol]()
# * [14.6 Sample Protocol: Transmission Control Protocol]()
# * [14.7 Dissecting a Frame]()
# * [14.8 Additional Resources]()
# * [14.9 What's Next?]()
# * [Problems]()

# 15.[ Chapter Fifteen: Introduction to Processor Architecture]()
# * [15.1 Organization versus Architecture]()
# * [15.2 Components]()
# * [15.2.1 Bus]()
# * [15.2.2 Registers]()
# * [15.2.3 Flags]()
# * [15.2.4 Buffers]()
# * [15.2.5 The Stack]()
# * [15.2.6 I/O Ports]()
# * [15.3 Processor Level]()
# * [15.4 CPU Level]()
# * [15.5 Simple Example of CPU Operation]()
# * [15.6 Assembly and Machine Language]()
# * [15.7 Big-Endian/Little-Endian]()
# * [15.8 Pipelined Architectures]()
# * [15.9 Passing Data To and From Peripherals]()
# * [15.9.1 Memory-Mapped I/O]()
# * [15.9.2 Polling]()
# * [15.9.3 Interrupts]()
# * [15.9.4 Direct Memory Access]()
# * [15.9.5 I/O Channels and Processors]()
# * [15.10 What's Next?]()
# * [Problems]()

# 16.[ Chapter Sixteen: Intel 80x86 Base Architecture]()
# * [16.1 Why Study the 80x86?]()
# * [16.2 Execution Unit]()
# * [16.2.1 General Purpose Registers]()
# * [16.2.2 Address Registers]()
# * [16.2.3 Flags]()
# * [16.2.4 Internal Buses]()
# * [16.3 Bus Interface Unit]()
# * [16.3.1 Segment Addressing]()
# * [16.3.2 Instruction Queue]()
# * [16.4 Memory versus I/O Ports]()
# * [16.5 What's Next?]()
# * [Problems]()

# 17.[ Chapter Seventeen: Intel 80x86 Assembly Language]()
# * [17.1 Assemblers versus Compilers]()
# * [17.2 Components of a Line of Assembly Language]()
# * [17.3 Assembly Language Directives]()
# * [17.3.1 SEGMENT Directive]()
# * [17.3.2 .MODEL, .STACK, .DATA, and .CODE Directives . 380 ]()
# * [17.3.3 PROC Directive]()
# * [17.3.4 END Directive]()
# * [17.3.5 Data Definition Directives]()
# * [17.3.6 EQU Directive]()
# * [17.4 80x86 Opcodes]()
# * [17.4.1 Data Transfer]()
# * [17.4.2 Data Manipulation]()
# * [17.4.3 Program Control]()
# * [17.4.4 Special Operations]()
# * [17.5 Addressing Modes]()
# * [17.5.1 Register Addressing]()
# * [17.5.2 Immediate Addressing]()
# * [17.5.3 Pointer Addressing]()
# * [17.6 Sample 80x86 Assembly Language Programs]()
# * [17.7 Additional 80x86 Programming Resources]()
# * [17.8 What's Next?]()
# * [Problems]()

